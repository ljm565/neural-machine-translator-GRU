# base
seed: 0
deterministic: True

# environment config
device: cpu     # examples: [0], [0,1], [1,2,3], cpu, mps... 

# project config
project: outputs/gru_w_attention
name: tatoeba

# model config
vocab_size: 10000
max_len: 32
num_layers: 1            # Number of GRU layers
hidden_dim: 768
dropout: 0
use_attention: True

# data config
workers: 0               # Don't worry to set worker. The number of workers will be set automatically according to the batch size.
tatoeba_train: True      # if True, tatoeba will be loaded automatically.
tatoeba:
    path: data/
CUSTOM:
    train_data_path: null
    validation_data_path: null
    test_data_path: null

# train config
batch_size: 128
epochs: 100
lr: 1e-3
teacher_forcing_ratio: 1
patience: 5                           # Early stopping epochs.
prediction_print_n: 10

# logging config
common: ['train_loss', 'validation_loss']
metrics: ['ppl', 'bleu2', 'bleu4', 'nist2', 'nist4']   # You can add more metrics after implements metric validation codes